# uncertainty-bench
Repository for **Benchmarking Scalable Predictive Uncertainty in Text Classification**, by Jordy Van Landeghem, Matthew Blaschko, Bertrand Anckaert and Marie-Francine Moens, JMLR 2020 (submitted).

It contains the source code of the paper, the experiments therein, and (slides) 
in the folders [`paper`](./paper), [`src`](./src), and [`experiments`](./experiments), respectively.

<!---
<img src="https://user-images.githubusercontent.com/5989894/82336026-5a9f2e80-99ea-11ea-8141-facbcf9fd60d.gif" width="350" alt="AOWS-teaser">
--->

## Data [TBD]

Link to used datasets with references
Might serve some in a google drive link.

## Usage

link to README of experiments

### Training a model
_main file: `experiment.py`_

Example command:
```
python3 experiment.py CONFIG_NAME
```

### Extending with your uncertainty method [TBD]


## Citation
```
@inproceedings{VanLandeghem2020a,
  TITLE = {Benchmarking Scalable Predictive Uncertainty in Text Classification},
  AUTHOR = {Van Landeghem, Jordy and Blaschko, Matthew B. and Anckaert, Bertrand and Moens, Marie-Francine},
  BOOKTITLE = {Submitted to Journal of Machine Learning Research},
  YEAR = {2020/1}
}
```

## Disclaimer
The code was originally run in a corporate environment, now reimplemented and open-sourced for helping the research community. 
There will be small changes between the current output & results presented in the paper.
