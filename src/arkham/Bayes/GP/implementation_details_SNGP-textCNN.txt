Conv2D specnorm params
=> big parameter increase! :O || spoiler

Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
word_input (InputLayer)         [(None, 200)]        0                                            
__________________________________________________________________________________________________
word_embedding (Embedding)      (None, 200, 100)     2000000     word_input[0][0]                 
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 200, 100, 1)  0           word_embedding[0][0]             
__________________________________________________________________________________________________
spectral_normalization_conv2d ( (None, 198, 1, 100)  2050100     lambda[0][0]                     
__________________________________________________________________________________________________
spectral_normalization_conv2d_1 (None, 197, 1, 100)  2060100     lambda[0][0]                     
__________________________________________________________________________________________________
spectral_normalization_conv2d_2 (None, 196, 1, 100)  2070100     lambda[0][0]                     
__________________________________________________________________________________________________
dropout (Dropout)               (None, 198, 1, 100)  0           spectral_normalization_conv2d[0][
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 197, 1, 100)  0           spectral_normalization_conv2d_1[0
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 196, 1, 100)  0           spectral_normalization_conv2d_2[0
__________________________________________________________________________________________________
max_pooling_3 (MaxPooling2D)    (None, 101, 1, 100)  0           dropout[0][0]                    
__________________________________________________________________________________________________
max_pooling_4 (MaxPooling2D)    (None, 101, 1, 100)  0           dropout_1[0][0]                  
__________________________________________________________________________________________________
max_pooling_5 (MaxPooling2D)    (None, 101, 1, 100)  0           dropout_2[0][0]                  
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 101, 1, 300)  0           max_pooling_3[0][0]              
                                                                 max_pooling_4[0][0]              
                                                                 max_pooling_5[0][0]              
__________________________________________________________________________________________________
flatten (Flatten)               (None, 30300)        0           concatenate[0][0]                
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30300)        0           flatten[0][0]                    
==================================================================================================
Total params: 8,180,300
Trainable params: 2,120,300
Non-trainable params: 6,060,000
__________________________________________________________________________________________________
(Pdb++) 

Conv1D specnorm params
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
word_input (InputLayer)         [(None, 200)]        0                                            
__________________________________________________________________________________________________
word_embedding (Embedding)      (None, 200, 100)     2000000     word_input[0][0]                 
__________________________________________________________________________________________________
conv1d (SpectralNormalization)  (None, 198, 100)     30500       word_embedding[0][0]             
__________________________________________________________________________________________________
conv1d_1 (SpectralNormalization (None, 197, 100)     40600       word_embedding[0][0]             
__________________________________________________________________________________________________
conv1d_2 (SpectralNormalization (None, 196, 100)     50700       word_embedding[0][0]             
__________________________________________________________________________________________________
dropout (Dropout)               (None, 198, 100)     0           conv1d[0][0]                     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 197, 100)     0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 196, 100)     0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d (GlobalMax (None, 100)          0           dropout[0][0]                    
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           dropout_1[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           dropout_2[0][0]                  
__________________________________________________________________________________________________
activation (Activation)         (None, 100)          0           global_max_pooling1d[0][0]       
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 100)          0           global_max_pooling1d_1[0][0]     
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 100)          0           global_max_pooling1d_2[0][0]     
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 300)          0           activation[0][0]                 
                                                                 activation_1[0][0]               
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 300)          0           concatenate[0][0]                
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 300)          0           activation_3[0][0]               
==================================================================================================
Total params: 2,121,800
Trainable params: 2,120,300
Non-trainable params: 1,500
__________________________________________________________________________________________________



Conv2D wrong specnorm

Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
word_input (InputLayer)         [(None, 200)]        0                                            
__________________________________________________________________________________________________
word_embedding (Embedding)      (None, 200, 100)     2000000     word_input[0][0]                 
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 200, 100, 1)  0           word_embedding[0][0]             
__________________________________________________________________________________________________
spectral_normalization (Spectra (None, 198, 1, 100)  30500       lambda[0][0]                     
__________________________________________________________________________________________________
spectral_normalization_1 (Spect (None, 197, 1, 100)  40600       lambda[0][0]                     
__________________________________________________________________________________________________
spectral_normalization_2 (Spect (None, 196, 1, 100)  50700       lambda[0][0]                     
__________________________________________________________________________________________________
dropout (Dropout)               (None, 198, 1, 100)  0           spectral_normalization[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 197, 1, 100)  0           spectral_normalization_1[0][0]   
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 196, 1, 100)  0           spectral_normalization_2[0][0]   
__________________________________________________________________________________________________
max_pooling_3 (MaxPooling2D)    (None, 101, 1, 100)  0           dropout[0][0]                    
__________________________________________________________________________________________________
max_pooling_4 (MaxPooling2D)    (None, 101, 1, 100)  0           dropout_1[0][0]                  
__________________________________________________________________________________________________
max_pooling_5 (MaxPooling2D)    (None, 101, 1, 100)  0           dropout_2[0][0]                  
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 101, 1, 300)  0           max_pooling_3[0][0]              
                                                                 max_pooling_4[0][0]              
                                                                 max_pooling_5[0][0]              
__________________________________________________________________________________________________
flatten (Flatten)               (None, 30300)        0           concatenate[0][0]                
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30300)        0           flatten[0][0]                    
==================================================================================================
Total params: 2,121,800
Trainable params: 2,120,300
Non-trainable params: 1,500
__________________________________________________________________________________________________


base_learning_rate
bert_ckpt_dir
bert_config_dir
bert_dir
checkpoint_interval
data_dir
eval_batch_size
evaluation_interval
gp_bias
gp_cov_discount_factor
gp_cov_ridge_penalty
gp_hidden_dim
[no]gp_input_normalization
gp_mean_field_factor
gp_scale
num_bins
num_cores
num_mc_samples
one_minus_momentum
output_dir
per_core_batch_size
seed
spec_norm_bound
spec_norm_iteration
tpu
train_epochs
[no]use_bfloat16
[no]use_gp_layer
[no]use_gpu
[no]use_layer_norm_att
[no]use_layer_norm_ffn
[no]use_spec_norm_att
[no]use_spec_norm_ffn
[no]use_spec_norm_plr
warmup_proportion

  --base_learning_rate: Base learning rate when total batch size is 128. It is
    scaled by the ratio of the total batch size to 128.
    (default: '5e-05')
    (a number)
  --bert_ckpt_dir: Directory to BERT pre-trained checkpoints. If None then then
    default to {bert_dir}/bert_model.ckpt.
  --bert_config_dir: Directory to BERT config files. If None then then default
    to {bert_dir}/bert_config.json.
  --bert_dir: Directory to BERT pre-trained checkpoints and config files.
  --checkpoint_interval: Number of epochs between saving checkpoints. Use -1 to
    never save checkpoints.
    (default: '40')
    (an integer)
  --data_dir: Directory containing the TFRecord datasets and the tokenizer for
    Clinc Intent Detection Data.
  --eval_batch_size: Batch size for CPU evaluation.
    (default: '512')
    (an integer)
  --evaluation_interval: Number of epochs between evaluation.
    (default: '2')
    (an integer)
  --gp_bias: The bias term for GP layer.
    (default: '0.0')
    (a number)
  --gp_cov_discount_factor: The discount factor to compute the moving average of
    precision matrix.
    (default: '0.999')
    (a number)
  --gp_cov_ridge_penalty: Ridge penalty parameter for GP posterior covariance.
    (default: '0.001')
    (a number)
  --gp_hidden_dim: The hidden dimension of the GP layer, which corresponds to
    the number of random features used for the approximation.
    (default: '2048')
    (an integer)
  --[no]gp_input_normalization: Whether to normalize the input using LayerNorm
    for GP layer.This is similar to automatic relevance determination (ARD) in
    the classic GP learning.
    (default: 'true')
  --gp_mean_field_factor: The tunable multiplicative factor used in the mean-
    field approximation for the posterior mean of softmax Gaussian process. If
    -1 then use posterior mode instead of posterior mean. See [2] for detail.
    (default: '0.1')
    (a number)
  --gp_scale: The length-scale parameter for the RBF kernel of the GP layer.
    (default: '2.0')
    (a number)
  --num_bins: Number of bins for ECE.
    (default: '15')
    (an integer)
  --num_cores: Number of TPU cores or number of GPUs.
    (default: '8')
    (an integer)
  --num_mc_samples: Number of Monte Carlo forward passes to collect for ensemble
    prediction.Currently can only be 1 since the model is deterministic.
    (default: '1')
    (an integer)
  --one_minus_momentum: Optimizer momentum.
    (default: '0.1')
    (a number)
  --output_dir: Output directory.
    (default: '/tmp/clinc_intent')
  --per_core_batch_size: Batch size per TPU core/GPU.
    (default: '64')
    (an integer)
  --seed: Random seed.
    (default: '42')
    (an integer)
  --spec_norm_bound: Upper bound to spectral norm of weight matrices.
    (default: '0.95')
    (a number)
  --spec_norm_iteration: Number of power iterations to perform for estimating
    the spectral norm of weight matrices.
    (default: '1')
    (an integer)
  --tpu: Name of the TPU. Only used if use_gpu is False.
  --train_epochs: Number of training epochs.
    (default: '40')
    (an integer)
  --[no]use_bfloat16: Whether to use mixed precision.
    (default: 'false')
  --[no]use_gp_layer: Whether to use Gaussian process as the output layer.
    (default: 'true')
  --[no]use_gpu: Whether to run on GPU or otherwise TPU.
    (default: 'false')
  --[no]use_layer_norm_att: Whether to apply layer normalization to the self-
    attention layers.
    (default: 'true')
  --[no]use_layer_norm_ffn: Whether to apply layer normalization to the
    feedforward layers.
    (default: 'true')
  --[no]use_spec_norm_att: Whether to apply spectral normalization to the self-
    attention layers.
    (default: 'false')
  --[no]use_spec_norm_ffn: Whether to apply spectral normalization to the
    feedforward layers.
    (default: 'false')
  --[no]use_spec_norm_plr: Whether to apply spectral normalization to the final
    CLS pooler layer.
    (default: 'true')
  --warmup_proportion: Proportion of training to perform linear learning rate
    warmup for. E.g., 0.1 = 10% of training.
    (default: '0.1')
    (a number)